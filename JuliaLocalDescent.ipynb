{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Descent\n",
    "\n",
    "In the general sense, local descent methods provide an optimization framework for solving multivariate functions to converge to some local minima based on some convergence criterion (i.e., gradient descent).\n",
    "\n",
    "A common approach is to incrementally improve the solution by taking steps in the descent direction (e.g., negative of gradient) of the function at the current point until a terminal or convergence condition is reached.\n",
    "\n",
    "$x_{k+t} = x_k + α_k * d_k$\n",
    "\n",
    "where $x_k$ is the current point, $α_k$ is the step size, and $d_k$ is the descent direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line Search\n",
    "\n",
    "In this first form of local descent, we will use a line search to find the optimal step size $α_k$ followed by computing the next point $x_{k+t}$.\n",
    "\n",
    "$minimize \\space f(x_k + α_k * d_k)$\n",
    "\n",
    "note this is still a univariate function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.1",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "name": "julia"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
